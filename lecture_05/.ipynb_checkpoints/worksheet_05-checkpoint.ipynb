{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
<<<<<<< HEAD
    "Name:  \n",
    "UID: \n",
=======
    "Name:  Zuizz Saeed, Jeremy Bui, Rithvik Nakirikanti\n",
    "UID: U08731461\n",
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "For each data point, we will calculate the distance to each centroid and assign the point to the closest centroid.\r\n",
    "Calculate distance:s\n",
    "0: 0,0.5,1.5,2,6,6.5,7\n",
    "2: 2,1.5,0.5,0,4,4.5,5\n",
    "Initial:\n",
    "C1: 0, 0.5\n",
    "C2: 1.5, 2, 6, 6.5, 7\n",
    "\n",
    "Compute the mean of the data points in each cluster and update the centroids.\n",
    "C1: Mean = 02.5\n",
    "C2: Mean = 4.6\n",
    "\n",
    "2nd iteration:\n",
    "C1: 0, 0.5, 1.5, 2\n",
    "C2: 6, 6.5, 7\n",
    "C1 mean = 1\n",
    "C2 mean = 6.5\n",
    "\n",
    "3rd iteration:\n",
    "C1: 0, 0.5, 1.5, 2\n",
    "C2: 6, 6.5, 7\n",
    "C1 mean = 1\n",
    "C2 mean = 6.5\n",
    "\n",
    "From here, it converges, so we are done. Final clusters:\n",
    "C1: 0, 0.5, 1.5, 2\n",
    "C2: 6, 6.5, 7:"
   ]
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "A cost function is a way to compare the outputs of this algorithm and is a way to build an algorithm based off of this metric. We want to minimize the cost function to find the best output. The objective of k-means clustering is to partition a given dataset into k clusters, where each data point belongs to the cluster with the nearest mean. The cost function measures how well the data points are clustered around their respective cluster centroids."
   ]
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "The initial random selection of cluster centers and the sensitivity to outliers can lead to different solutions because the algorithm may converge to different local centroids of the cost function, resulting in varied cluster assignments and center positions."
   ]
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
<<<<<<< HEAD
   "source": []
=======
   "source": [
    "Lloydâ€™s algorithm is guaranteed to converge because it is a greedy algorithm that keeps decreasing the value of objective function. However, it\r\n",
    "may only converge to a local minimum and thus a good initializer is needed If we have a finite number of datapoints, then we can deduce that there are only a finite number of ways to group these datapoints into K clusters.."
   ]
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.64577262  1.63809959]\n",
      " [ 2.84802091 -4.22646665]\n",
      " [ 1.06508012 -3.40764942]\n",
      " [-2.36301551  1.35891735]]\n",
      "[[ 1.53559733  1.5172108 ]\n",
      " [ 2.63069121 -4.35943319]\n",
      " [ 0.94925723 -3.26808424]\n",
      " [-2.51092756  1.45100913]]\n",
      "[[ 1.45171042  1.47682367]\n",
      " [ 2.3997613  -4.39430201]\n",
      " [ 0.80730524 -2.94455245]\n",
      " [-2.64120128  1.51704576]]\n",
      "[[ 1.44883679  1.49864424]\n",
      " [ 2.23639482 -4.36544771]\n",
      " [ 0.68760098 -2.55182683]\n",
      " [-2.66317601  1.53720163]]\n",
      "[[ 1.49489191  1.54989961]\n",
      " [ 2.08667972 -4.3512857 ]\n",
      " [ 0.44089571 -1.8653467 ]\n",
      " [-2.72500525  1.60010322]]\n",
      "[[ 1.54931661  1.64999546]\n",
      " [ 2.01748442 -4.33560966]\n",
      " [ 0.31833923 -1.31916812]\n",
      " [-2.8062043   1.6770794 ]]\n",
      "[[ 1.67389817  1.84623353]\n",
      " [ 1.9196849  -4.2577017 ]\n",
      " [ 0.20744995 -0.68995839]\n",
      " [-2.90101537  1.7680821 ]]\n",
      "[[ 1.79136962  1.93703117]\n",
      " [ 1.87039274 -4.15046079]\n",
      " [ 0.12529588 -0.33827988]\n",
      " [-2.90101537  1.7680821 ]]\n",
      "[[ 1.81283979  1.96616707]\n",
      " [ 1.84012274 -4.13675116]\n",
      " [ 0.05427602 -0.16509598]\n",
      " [-3.00866911  1.82497252]]\n",
      "[[ 1.88840724  1.99930769]\n",
      " [ 1.84012274 -4.13675116]\n",
      " [ 0.02609039 -0.0539465 ]\n",
      " [-3.04862622  1.85340542]]\n",
      "[[ 1.91248297e+00  2.00204407e+00]\n",
      " [ 1.84012274e+00 -4.13675116e+00]\n",
      " [ 1.33733963e-02 -3.71451966e-04]\n",
      " [-3.07703402e+00  1.85266958e+00]]\n",
      "[[ 1.91248297e+00  2.00204407e+00]\n",
      " [ 1.84012274e+00 -4.13675116e+00]\n",
      " [ 1.33733963e-02 -3.71451966e-04]\n",
      " [-3.07703402e+00  1.85266958e+00]]\n"
     ]
    }
   ],
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
<<<<<<< HEAD
    "\n",
    "\n",
    "    def lloyds(self):\n",
    "        ...\n",
    "        return\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 6)\n",
=======
    "        \n",
    "    def is_unassigned(self, i):\n",
    "        return self.assignment[i] == -1\n",
    "    \n",
    "    def unassign_all(self):\n",
    "        self.assignment = [-1 for _ in range(len(self.data))]\n",
    "        \n",
    "    def initialize(self):\n",
    "        return self.data[np.random.choice(range(len(self.data)), size=self.k, replace=False)]\n",
    "    \n",
    "    def are_centers_diff(self, c1, c2):\n",
    "        for i in range(len(c1)):\n",
    "            if c1[i] not in c2:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def assign(self, centers):\n",
    "        for i in range(len(self.data)):\n",
    "            self.assignment[i] = 0\n",
    "            temp_assign = 0\n",
    "            temp_dist = self.dist(self.data[i], centers[0])\n",
    "            for j in range(1, len(centers)):\n",
    "                new_dist = self.dist(self.data[i], centers[j])\n",
    "                if temp_dist > new_dist:\n",
    "                    self.assignment[i] = j\n",
    "                    temp_dist = new_dist\n",
    "    \n",
    "    def calculate_new_centers(self):\n",
    "        centers = []\n",
    "        for j in range(self.k):\n",
    "            cluster_j = self.data[\n",
    "                np.array([i for i in range(len(self.data)) if self.assignment[i] == j])\n",
    "            ]\n",
    "            centers.append(np.mean(cluster_j,axis=0))\n",
    "        \n",
    "        return np.array(centers)\n",
    "\n",
    "    def dist(self, x, y):\n",
    "        return sum((x - y) ** 2) ** (1/2)\n",
    "\n",
    "    def lloyds(self):\n",
    "        centers = self.initialize()\n",
    "        self.assign(centers)\n",
    "        self.snap(centers)\n",
    "        new_centers = self.calculate_new_centers()\n",
    "        while self.are_centers_diff(centers, new_centers):\n",
    "            centers = new_centers\n",
    "            self.snap(centers)\n",
    "            self.unassign_all()\n",
    "            self.assign(centers)\n",
    "            new_centers = self.calculate_new_centers()\n",
    "            print (new_centers)\n",
    "        return\n",
    "            \n",
    "kmeans = KMeans(X, 4)\n",
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
=======
   "display_name": "Python 3 (ipykernel)",
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
   "language": "python",
   "name": "python3"
  },
  "language_info": {
<<<<<<< HEAD
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
=======
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
<<<<<<< HEAD
 "nbformat_minor": 2
=======
 "nbformat_minor": 4
>>>>>>> d57cd6d70986651bf8da71c3a67b6f2b8f17e15c
}
